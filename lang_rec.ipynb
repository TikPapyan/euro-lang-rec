{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import multiprocessing\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "t8A2wnTFTa1X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSWRmz3oSMsB",
        "outputId": "77b5ac7e-7ad1-46f5-d26a-0758f2a8f8c4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/basilb2s/language-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"basilb2s/language-detection\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(path, \"Language Detection.csv\"))\n",
        "print(f\"{df.head()} \\n\")\n",
        "print(f\"{df.columns} \\n\")\n",
        "print(f\"{df['Language'].unique()} \\n\")\n",
        "print(f\"Number of rows - {(df.shape[0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxuvgpd_TEn_",
        "outputId": "def617c9-5619-4163-fe5e-b9eb499ebeee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text Language\n",
            "0   Nature, in the broadest sense, is the natural...  English\n",
            "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
            "2  The study of nature is a large, if not the onl...  English\n",
            "3  Although humans are part of nature, human acti...  English\n",
            "4  [1] The word nature is borrowed from the Old F...  English \n",
            "\n",
            "Index(['Text', 'Language'], dtype='object') \n",
            "\n",
            "['English' 'Malayalam' 'Hindi' 'Tamil' 'Portugeese' 'French' 'Dutch'\n",
            " 'Spanish' 'Greek' 'Russian' 'Danish' 'Italian' 'Turkish' 'Sweedish'\n",
            " 'Arabic' 'German' 'Kannada'] \n",
            "\n",
            "Number of rows - 10337 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[df[\"Text\"].str.split().str.len() < 4]\n",
        "print(df_filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYB8y7_97Mxl",
        "outputId": "eb671416-7ade-4f81-8bf0-ec0c0ec080fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    Text Language\n",
            "347                             Kennedy.  English\n",
            "750                                GNE).  English\n",
            "1074                        wasn't able.  English\n",
            "1100                        how are you?  English\n",
            "1102                    how's it going?.  English\n",
            "...                                  ...      ...\n",
            "10275  ನಾನು ನಿಮ್ಮೊಂದಿಗೆ ಸರಿಯಾಗಿರುತ್ತೇನೆ.  Kannada\n",
            "10276                 ಕ್ಷಮೆಯಾಚಿಸುತ್ತಿದೆ.  Kannada\n",
            "10279              ಅದರ ಬಗ್ಗೆ ಚಿಂತಿಸಬೇಡಿ.  Kannada\n",
            "10280                        ಚಿಂತಿಸಬೇಡಿ.  Kannada\n",
            "10320                      ನೀನು ತಿನ್ನು.  Kannada\n",
            "\n",
            "[1156 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~((df[\"Text\"].str.split().str.len() == 1) & (df[\"Text\"].str.len() < 3))]\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "CFZMC5M0-gxC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ABBREVIATIONS = set([\n",
        "    # **English**\n",
        "    \"p.m.\", \"a.m.\", \"dr.\", \"mr.\", \"mrs.\", \"u.s.a.\", \"e.g.\", \"i.e.\", \"etc.\", \"vs.\", \"fig.\", \"vol.\", \"no.\", \"pp.\", \"gov.\", \"dept.\", \"lt.\", \"gen.\", \"inc.\", \"corp.\", \"est.\", \"prof.\", \"ph.d.\", \"jr.\", \"sr.\", \"st.\", \"mt.\", \"rev.\", \"ft.\", \"sq.\", \"yr.\", \"min.\", \"sec.\",\n",
        "\n",
        "    # **French**\n",
        "    \"m.\", \"mme.\", \"mlle.\", \"dr.\", \"av.\", \"boul.\", \"ch.\", \"fig.\", \"etc.\", \"p.ex.\", \"cf.\", \"ibid.\", \"op.cit.\", \"c.-à-d.\", \"n.b.\", \"p.j.\", \"t.s.v.p.\", \"env.\", \"gov.\", \"dir.\", \"adm.\", \"prof.\", \"ph.d.\",\n",
        "\n",
        "    # **German**\n",
        "    \"p.m.\", \"a.m.\", \"d.h.\", \"z.B.\", \"u.a.\", \"etc.\", \"vgl.\", \"usw.\", \"bzw.\", \"ff.\", \"u.E.\", \"g.U.\", \"g.g.A.\", \"Buchst.\", \"u.s.w.\", \"sog.\", \"u.ä.\", \"Std.\", \"evtl.\", \"Zt.\", \"Chr.\", \"u.U.\", \"o.ä.\", \"Ltd.\", \"b.A.\", \"z.Zt.\", \"spp.\", \"sen.\", \"SA\", \"k.o.\", \"jun.\", \"i.H.v.\", \"dgl.\", \"dergl.\", \"Co.\", \"zzt.\", \"usf.\", \"s.p.a.\", \"Dkr.\", \"Corp.\", \"bzgl.\", \"BSE\",\n",
        "\n",
        "    # **Spanish**\n",
        "    \"p.ej.\", \"etc.\", \"s.a.\", \"sr.\", \"sra.\", \"dr.\", \"prof.\", \"pág.\", \"núm.\", \"gral.\", \"av.\", \"c/\", \"dpto.\", \"c.c.\", \"ud.\", \"u.d.\", \"u.s.\", \"u.v.\", \"a.c.\", \"d.c.\", \"admón.\", \"corp.\",\n",
        "\n",
        "    # **Portuguese**\n",
        "    \"sr.\", \"sra.\", \"dr.\", \"prof.\", \"av.\", \"pág.\", \"etc.\", \"ex.\", \"obs.\", \"exmo.\", \"adm.\", \"corp.\", \"ilmo.\", \"u.s.\", \"u.v.\", \"a.c.\", \"d.c.\", \"n.º\", \"s.l.\", \"fasc.\",\n",
        "\n",
        "    # **Dutch**\n",
        "    \"blz.\", \"bijv.\", \"ca.\", \"dhr.\", \"dr.\", \"e.d.\", \"e.v.\", \"enz.\", \"fig.\", \"gem.\", \"i.h.b.\", \"m.a.w.\", \"m.n.\", \"m.v.g.\", \"n.a.v.\", \"nr.\", \"o.a.\", \"o.i.\", \"p.m.\", \"pag.\", \"t.o.v.\", \"t.z.t.\", \"vlg.\", \"zgn.\", \"z.i.\", \"z.s.m.\", \"z.v.h.\",\n",
        "\n",
        "    # **Italian**\n",
        "    \"sig.\", \"sig.ra\", \"sig.na\", \"ecc.\", \"dr.\", \"prof.\", \"s.p.a.\", \"s.r.l.\", \"es.\", \"avv.\", \"ing.\", \"dott.\", \"p.zza\", \"v.le\", \"c.so\", \"b.s.\", \"c.m.\", \"s.n.c.\", \"n.b.\", \"c.c.\",\n",
        "\n",
        "    # **Swedish**\n",
        "    \"bl.a.\", \"d.v.s.\", \"m.fl.\", \"m.m.\", \"nr.\", \"o.s.v.\", \"s.a.s.\", \"t.ex.\", \"m.a.o.\", \"jfr.\", \"ibid.\", \"c:a\", \"p.g.a.\", \"m.h.t.\", \"d.g.s.\", \"d.o.\",\n",
        "\n",
        "    # **Danish**\n",
        "    \"bl.a.\", \"ca.\", \"dvs.\", \"m.fl.\", \"m.m.\", \"nr.\", \"osv.\", \"t.ex.\", \"m.a.o.\", \"jfr.\", \"ibid.\", \"c:a\", \"p.g.a.\", \"f.eks.\", \"mht.\", \"a.s.\", \"cvr.\",\n",
        "\n",
        "    # **Greek**\n",
        "    \"κλπ.\", \"π.χ.\", \"δηλ.\", \"κ.α.\", \"ο.ε.\", \"σ.σ.\", \"βλ.\", \"περ.\", \"σελ.\", \"κα.\", \"γ.τ.λ.\", \"γ.τ.κ.\",\n",
        "\n",
        "    # **Russian**\n",
        "    \"и т.д.\", \"и др.\", \"и пр.\", \"г.\", \"ул.\", \"д.\", \"кв.\", \"км.\", \"см.\", \"т.е.\", \"напр.\", \"ср.\", \"с.г.\", \"п.р.\", \"ч.п.\", \"с.г.\", \"с.р.\",\n",
        "\n",
        "    # **Turkish**\n",
        "    \"sn.\", \"dr.\", \"öğr.\", \"av.\", \"doç.\", \"prof.\", \"vs.\", \"ör.\", \"sf.\", \"ç.\", \"müh.\", \"gen.\", \"alb.\", \"uzm.\", \"şb.\",\n",
        "\n",
        "    # **Malayalam**\n",
        "    \"വി.\", \"മൂ.\", \"വി.ക.\", \"ന.ക.\", \"ഉപ.\", \"പൂ.ന.\", \"ചി.\", \"പി.\", \"ബി.\", \"ടി.\", \"ഡി.\", \"ഡി.ആർ.\", \"വി.ഡി.\",\n",
        "\n",
        "    # **Hindi**\n",
        "    \"डॉ.\", \"श्री.\", \"संपा.\", \"सं.\", \"संपा.\", \"नि.\", \"नि.सं.\", \"वि.\", \"वि.वि.\", \"सं.सं.\",\n",
        "\n",
        "    # **Tamil**\n",
        "    \"செ.\", \"நா.\", \"தி.\", \"பி.\", \"க.\", \"மு.\", \"ச.\", \"ப.\", \"ஆ.\", \"பி.எச்.டி.\",\n",
        "\n",
        "    # **Kannada**\n",
        "    \"ಶ್ರೀ.\", \"ವಿ.\", \"ಡಾ.\", \"ಪ್ರೊ.\", \"ನೋ.\", \"ಗ.ಶಿ.\", \"ಚ.ಚಿ.\", \"ಸಂಪಾ.\", \"ಸಂ.\", \"ವಿ.ವಿ.\", \"ಅ.ಪ್ರ.\",\n",
        "\n",
        "    # **Arabic**\n",
        "    \"د.\", \"م.\", \"أ.\", \"ج.\", \"س.\", \"ك.\", \"ن.\", \"ب.\", \"ش.\", \"ع.\", \"هـ.\"\n",
        "])"
      ],
      "metadata": {
        "id": "m9g9F0Gs-zcl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower().strip()\n",
        "\n",
        "  for abbr in ABBREVIATIONS:\n",
        "      text = text.replace(abbr, abbr.replace('.', ''))\n",
        "\n",
        "  text = re.sub(r'[^\\p{L}\\s]', '', text)\n",
        "\n",
        "  return text.strip()\n",
        "\n",
        "df['Cleaned_Text'] = df['Text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "vH2VJH9zTPQh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_trigrams(text):\n",
        "  if len(text) < 3:\n",
        "      return []\n",
        "  trigrams = [text[i:i+3] for i in range(len(text)-2)]\n",
        "  return trigrams"
      ],
      "metadata": {
        "id": "aPvZu3n25lQI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "df['Trigrams'] = df['Cleaned_Text'].apply(extract_trigrams)\n",
        "\n",
        "end_time = time.time()\n",
        "trigram_time = end_time - start_time\n",
        "print(f\"Time for trigram extraction: {round(trigram_time, 4)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3douu3pGN6vg",
        "outputId": "c0205ab9-3245-4bc7-e7fa-f067a4513ad7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for trigram extraction: 0.6132 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = 10000\n",
        "trigram_map = {}\n",
        "\n",
        "def generate_vector(trigram):\n",
        "  if trigram not in trigram_map:\n",
        "      trigram_map[trigram] = np.random.choice([-1, 1], D)\n",
        "  return trigram_map[trigram]\n",
        "\n",
        "def calculate_hypervector(trigrams):\n",
        "  vector = np.sum([generate_vector(t) for t in trigrams], axis=0)\n",
        "  return vector / np.linalg.norm(vector)\n",
        "\n",
        "df_filtered = df[df['Trigrams'].apply(lambda x: len(x) > 0)].copy()"
      ],
      "metadata": {
        "id": "x_3gfkrc52Yp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "df_filtered.loc[:, 'Hypervector'] = df_filtered['Trigrams'].apply(calculate_hypervector)\n",
        "\n",
        "end_time = time.time()\n",
        "trigram_time = end_time - start_time\n",
        "print(f\"Time for training phase: {round(trigram_time, 4)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr0QzeSJ6AFV",
        "outputId": "210f43f8-b18f-4cdc-e3cf-1dcf89fc5a91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for training phase: 45.8002 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_train_test_split(df, test_size=0.2, random_state=42):\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df['Language'])\n",
        "\n",
        "    test_invalid_rows = test_df[test_df['Cleaned_Text'].str.split().str.len() < 4]\n",
        "\n",
        "    train_df = pd.concat([train_df, test_invalid_rows])\n",
        "\n",
        "    test_df = test_df[test_df['Cleaned_Text'].str.split().str.len() >= 4]\n",
        "\n",
        "    rows_to_move = len(test_invalid_rows)\n",
        "\n",
        "    train_valid_rows = train_df[train_df['Cleaned_Text'].str.split().str.len() > 4]\n",
        "    additional_rows = train_valid_rows.sample(n=rows_to_move, random_state=random_state)\n",
        "\n",
        "    test_df = pd.concat([test_df, additional_rows])\n",
        "\n",
        "    train_df = train_df.drop(additional_rows.index)\n",
        "\n",
        "    test_df = test_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    train_df = train_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "cd2nBsEgJcJN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_vectors = {}\n",
        "\n",
        "train_df, test_df = prepare_train_test_split(df_filtered)\n",
        "\n",
        "for lang in train_df['Language'].unique():\n",
        "    vectors = np.array(train_df[train_df['Language'] == lang]['Hypervector'].tolist())\n",
        "    language_vectors[lang] = np.mean(vectors, axis=0)"
      ],
      "metadata": {
        "id": "0AZArFDPKBbc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_language(hypervector, language_vectors):\n",
        "    similarities = {lang: cosine_similarity([hypervector], [vec])[0][0] for lang, vec in language_vectors.items()}\n",
        "    return max(similarities, key=similarities.get)"
      ],
      "metadata": {
        "id": "ExT36eD1Jcpf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "test_df['Predicted_Language'] = test_df['Hypervector'].apply(lambda x: predict_language(x, language_vectors))\n",
        "\n",
        "end_time = time.time()\n",
        "trigram_time = end_time - start_time\n",
        "print(f\"Time for prediction phase: {round(trigram_time, 4)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqXKo5-MJmqP",
        "outputId": "ca52d1f4-2743-4510-ff90-622a5de64bc1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for prediction phase: 22.1326 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(test_df['Language'], test_df['Predicted_Language'])\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auskF4lyMpwA",
        "outputId": "b9bab5f6-ab5a-405e-9131-e277ca29453a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mispredictions = test_df[test_df['Language'] != test_df['Predicted_Language']]\n",
        "\n",
        "print(f\"Wrong predictions \\n\")\n",
        "print(mispredictions[['Text', 'Language', 'Predicted_Language']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glOrov4cdAu7",
        "outputId": "85894344-85e1-46b9-fdea-877dc83f0ae7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrong predictions \n",
            "\n",
            "                                                  Text  Language  \\\n",
            "9                   oye cálmate juntos otra frase que.   Spanish   \n",
            "45             dina vänner jag känner mig mycket trög.  Sweedish   \n",
            "57   Des associations de ce type sont présentes en ...    French   \n",
            "321  [58] Three broad categories of anomaly detecti...   English   \n",
            "378                           Jag håller 100% med dig.  Sweedish   \n",
            "\n",
            "    Predicted_Language  \n",
            "9           Portugeese  \n",
            "45              Danish  \n",
            "57               Dutch  \n",
            "321             French  \n",
            "378             Danish  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Это простой русский текст\"\n",
        "cleaned_text = clean_text(new_text)\n",
        "trigrams = extract_trigrams(cleaned_text)\n",
        "hypervector = calculate_hypervector(trigrams)\n",
        "predicted_language = predict_language(hypervector, language_vectors)\n",
        "\n",
        "print(f\"Predicted Language: {predicted_language}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68mazHEpM8FY",
        "outputId": "00c2e4af-c6fb-45c3-ce48-424aa247847a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Language: Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yf2tzKmIdJA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}